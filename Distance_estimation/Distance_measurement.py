import os

import cv2
import numpy as np
from matplotlib import pyplot as plt

BOTTOM_PERCENTILE = 60


def fill_contour(contour):
    """
    Fills a contour generated by opencv. This function fills missing x-value gaps, and y-values are found though linear
    interpolation
    :param contour: The contour generated by opencv
    :return: filled contour
    """
    contour_x = contour[:, 0]
    contour_y = contour[:, 1]

    toReturn_x = []
    toReturn_y = []

    for i in range(len(contour_x) - 1):
        curr_x = contour_x[i]
        next_x = contour_x[i + 1]
        curr_y = contour_y[i]
        next_y = contour_y[i + 1]

        try:
            test_number = abs(next_x - curr_x)

            if test_number > 1000:
                print()
        except RuntimeWarning:
            print()

        if abs(next_x - curr_x) > 1:
            x_array = [curr_x, next_x]
            y_array = [curr_y, next_y]
            z = np.polyfit(x_array, y_array, 1)
            f = np.poly1d(z)

            for x in range(curr_x, next_x):
                y = f(x)
                toReturn_x.append(x)
                toReturn_y.append(y)

        else:
            toReturn_x.append(curr_x)
            toReturn_y.append(curr_y)

    toReturn_x.append(contour_x[-1])
    toReturn_y.append(contour_y[-1])

    toReturn = np.row_stack((toReturn_x, toReturn_y))
    toReturn = np.transpose(toReturn.astype(np.int32))
    return toReturn


def findDistance(center, bottom_contour):
    """
    Find the distance from the template center (spine bump) to the top bottom contour.
    :param center: The center location for the template, i.e. the spine bump
    :param bottom_contour: The bottom contour of the LP portion
    :return: the height from center to bottom contour
    """
    x = center[0]
    bottom_contour = fill_contour(bottom_contour)
    bottom_contour_x = bottom_contour[:, 0]
    bottom_contour_y = bottom_contour[:, 1]

    max_x = np.max(bottom_contour_x)
    min_x = np.min(bottom_contour_x)

    if (x > max_x) or (x < min_x):
        return -1

    range_beginning = 8

    in_range_index = np.where((x <= bottom_contour_x) & (bottom_contour_x < x + range_beginning))
    maximum_iterations = 1e3

    counter = 0
    while len(in_range_index[0]) <= 5:
        range_beginning += 1
        in_range_index = np.where((x <= bottom_contour_x) & (bottom_contour_x < x + range_beginning))
        if counter > maximum_iterations:
            return -1
        counter += 1

    in_range_y = bottom_contour_y[in_range_index]
    avg_y = np.average(in_range_y)
    distance = center[1] - avg_y

    return distance


def morph_closing(img_bw, kernel_height=3, kernel_width=None):
    """
    Performs a morphological closing. Removes potential breakages in contour
    :param img_bw: A thresholded BW image
    :param kernel_height: Kernel height for the morph operation
    :param kernel_width: Kernel width for the morph operation
    :return: A BW image after the morph closing operation
    """
    if kernel_width is None:
        kernel_width = kernel_height

    if (len(np.unique(img_bw)) != 2):
        import matplotlib.pyplot as plt
        plt.imshow(img_bw)
    assert len(np.unique(img_bw)) == 2, "Input image is not BW"
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_width, kernel_height))
    closing = cv2.morphologyEx(img_bw, cv2.MORPH_CLOSE, kernel)
    return closing


def pixel_by_percentile(img_gray, percentile):
    """
    Determine the pixel intensity by percentile, all black pixels are excluded
    :param img_gray: a BW image
    :param percentile: The percentile the user wish to achieve in the image
    :return: an int value for the pixel
    """
    if len(img_gray.shape) == 3:
        img_gray = cv2.cvtColor(img_gray, cv2.COLOR_BGR2GRAY)

    assert len(img_gray.shape) == 2, "Error in image channels"
    img_gray = np.array(img_gray)
    img_gray.flatten()
    non_zero_array = img_gray[img_gray != 0]
    thresh_value = np.percentile(non_zero_array, percentile)
    return thresh_value


def get_largest_cc(img_bw):
    """
    Separates out the largest connected component in the image, and turns every other pixel values to be 0
    :param img_bw: a BW image for separation
    :return: a BW image, in the original size, that only contains the largest connected component
    """
    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(img_bw, connectivity=8)
    stats_copy = stats.copy()
    areas = stats_copy[:, -1]
    areas.sort()
    largest_area = areas[-2]  # -1 is for the black background region

    location = np.where(stats == largest_area)
    label = location[0][0]
    largest_only = labels == label
    largest_only = np.array(largest_only, dtype=np.uint8)
    largest_only *= 255

    return largest_only


def get_longest_contour(contours):
    """
    Finds the longest contour within a contour list. This methods should be used to separate out the outer most contour
    from the inner contour of a component
    :param contours: a list of contours
    :return: index for the longest contour in the list
    """
    max_contour_len = 0
    max_contour_index = 0
    counter = 0

    for each_contour in contours:
        if len(each_contour) > max_contour_len:
            max_contour_len = len(each_contour)
            max_contour_index = counter
        counter += 1

    return max_contour_index


def contour_reduction(largest_contour):
    """
    Obtain an approximation, or LPF, of the contour, and then separate out the bottom section of it. Half separation is
    determined by the min and max x coordinates.
    :param largest_contour:
    :return: The bottom half of the approximated contour
    """
    ep = 0.005 * cv2.arcLength(largest_contour, True)
    approx = cv2.approxPolyDP(largest_contour, ep, True)
    bottom_half_contour = get_bottom_half(approx)
    # plot_contour_trend(bottom_half_contour)

    return bottom_half_contour


def get_bottom_half(contour):
    """
    Gets the bottom half of the the contour
    :param contour:
    :return:
    """
    contour = np.squeeze(contour)

    contour_x = contour.copy()[:, 0]
    contour_y = contour.copy()[:, 1]

    contour_x_min = np.min(contour_x)
    contour_x_max = np.max(contour_x)

    x_min_index = np.where(contour[:, 0] == contour_x_min)
    x_max_index = np.where(contour[:, 0] == contour_x_max)
    x_min_index = x_min_index[0]
    x_max_index = x_max_index[0]

    if len(x_min_index) != 1:
        beginning_candidate_y = contour_y[x_min_index]
        max_y = np.max(beginning_candidate_y)
        beginning_index = np.where(contour_y == max_y)
        x_set_b = set(x_min_index)
        y_set_b = set(beginning_index[0])
        common_index_b = x_set_b & y_set_b
        beginning_index = common_index_b.pop()
    else:
        beginning_index = x_min_index[0]

    if len(x_max_index) != 1:
        end_candidate_y = contour_y[x_max_index]
        max_y = np.max(end_candidate_y)
        ending_index = np.where(contour_y == max_y)
        x_set_e = set(x_max_index)
        y_set_e = set(ending_index[0])
        common_index_e = x_set_e & y_set_e
        ending_index = common_index_e.pop()
    else:
        ending_index = x_max_index[0]

    return contour[beginning_index:ending_index + 1, :]


def find_lumbodorsal_bottom(top_portion, reduction=True, imshow=False):
    """
    *** USING THIS METHOD IS DISCOURAGED, IT DOES NOT PRODUCE RELIABLE UPPER BOUNDARY ***
    For Case 4, this finds the bottom contour of the Lumodorsal Fascia
    :param top_portion: The top portion of the no ruler image to do the segmentation
    :param reduction: whether to use reduction to appriximate contour
    :return: The bottom contour of the Upper region of interest
    """

    from warnings import warn
    warn("Using this method to find upper boundary is discouraged, use find_lumbodorsal_bottom_1 instead")
    successful_detection = False
    if len(top_portion.shape) == 3:
        top_portion = cv2.cvtColor(top_portion, cv2.COLOR_BGR2GRAY)
    value = pixel_by_percentile(top_portion, BOTTOM_PERCENTILE)
    _, th = cv2.threshold(top_portion, value, 255, cv2.THRESH_BINARY)
    largest_binary = get_largest_cc(th)
    contours, _ = cv2.findContours(largest_binary, 1, 2)
    largest_contour_index = get_longest_contour(contours)
    if reduction:
        largest_contour = contour_reduction(contours[largest_contour_index])
    else:
        largest_contour = get_bottom_half(contours[largest_contour_index])

    if imshow:
        top_portion_color = cv2.cvtColor(top_portion, cv2.COLOR_GRAY2BGR)
        contour_img = cv2.polylines(top_portion_color, [largest_contour], False, (0, 255, 0), 2)
        cv2.imshow('TOP', contour_img)
        cv2.waitKey(0)

    if len(largest_contour) != 0:
        successful_detection = True

    return largest_contour, successful_detection


def find_lumbodorsal_bottom_1(top_portion, figure_name, imshow=False):
    marked_frame_path = r'C:\Users\Grant\Downloads\marked_frame (1)\marked_frame'
    marked_frame_name = os.path.join(marked_frame_path, figure_name)
    marked_frame = cv2.imread(marked_frame_name)

    successful_detection = False
    kernel_size = 25
    if len(top_portion.shape) == 3:
        top_portion = cv2.cvtColor(top_portion, cv2.COLOR_BGR2GRAY)

    top_boundary, bottom_boundary = ultrasound_boundary(top_portion)

    sobely = cv2.Sobel(top_portion, cv2.CV_64F, 0, 1, ksize=kernel_size)
    sobely -= sobely.min()
    sobely /= sobely.max()
    sobely *= 255
    sobely = np.array(sobely, dtype=np.uint8)

    sobely_edge = cv2.Canny(sobely, 20, 200)
    dilation_kernel = np.ones((3, 3), np.uint8)
    dilation_kernel = np.array([[1, 1, 1, 1, 1, 1]], dtype=np.uint8)
    dilated_edge = cv2.dilate(sobely_edge, dilation_kernel, iterations=1)
    dilated_edge = cv2.erode(dilated_edge, dilation_kernel)
    # dilated_edge_edge = cv2.Canny(dilated_edge, 50, 210)
    # stats includes [top, left, width, height, area]
    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(dilated_edge, connectivity=8)

    plt.subplot(2, 2, 1), plt.imshow(top_portion, cmap='gray')
    plt.subplot(2, 2, 2), plt.imshow(sobely)
    dilated_edge = cv2.cvtColor(dilated_edge, cv2.COLOR_GRAY2BGR)

    dilated_edge = cv2.line(dilated_edge, (top_boundary[0], 0), (bottom_boundary[0], top_portion.shape[0]), (0, 0, 0),
                            16)
    dilated_edge = cv2.line(dilated_edge, (top_boundary[1], 0), (bottom_boundary[1], top_portion.shape[0]), (0, 0, 0),
                            16)

    dilated_edge_bw = cv2.cvtColor(dilated_edge, cv2.COLOR_BGR2GRAY)

    dilated_edge = cv2.line(dilated_edge, (top_boundary[0], 0), (bottom_boundary[0], top_portion.shape[0]), (255, 0, 0),
                            2)
    dilated_edge = cv2.line(dilated_edge, (top_boundary[1], 0), (bottom_boundary[1], top_portion.shape[0]), (255, 0, 0),
                            2)
    plt.subplot(2, 2, 3), plt.imshow(dilated_edge, cmap='gray')
    connected_lines = splitting_lines(dilated_edge_bw, kernel_size=5)


    plt.subplot(2, 2, 4), plt.imshow(connected_lines, cmap='gray')

    plt.title(figure_name)
    figManager = plt.get_current_fig_manager()
    figManager.window.showMaximized()
    plt.show()


def splitting_lines(edge_img, kernel_size=5):
    """
    This function will mark the lines that should not be connected together
    :param kernel_size:
    :param normalized_img:
    :return:
    """

    r, c = edge_img.shape
    r_lim = r-2
    c_lim = c-2

    center_offset = int(np.floor(kernel_size/2))
    line_stick_marking = np.zeros_like(edge_img)

    for i in range(r_lim):
        for j in range(c_lim):

            sub_region = edge_img[i:i+kernel_size, j:j+kernel_size]
            center_pixel = sub_region[center_offset, center_offset]

            if center_pixel != 0:
                num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(sub_region, connectivity=8)
                center_pixel_label = labels[center_offset, center_offset]
                same_labelled_img = labels == center_pixel_label

                q1_exist = np.sum(same_labelled_img[0:center_offset, kernel_size-center_offset:kernel_size]) > 0
                q2_exist = np.sum(same_labelled_img[0:center_offset, 0:center_offset]) > 0
                q3_exist = np.sum(same_labelled_img[kernel_size-center_offset:kernel_size, 0:center_offset]) > 0
                q4_exist = np.sum(same_labelled_img[kernel_size-center_offset:kernel_size, kernel_size-center_offset:kernel_size]) > 0

                if q1_exist and q4_exist:
                    line_stick_marking[i+center_offset, j+center_offset] = 1
                elif q2_exist and q3_exist:
                    line_stick_marking[i+center_offset, j+center_offset] = 1

    points_to_remove = np.array(1-line_stick_marking, dtype=np.uint8)

    return np.array(cv2.bitwise_and(edge_img, points_to_remove)*255, dtype=np.uint8)


def ultrasound_boundary(img):
    """
    Finds the bounding shape for the ultrasound image
    :param img:
    :return:
    """
    if len(img.shape) == 3:
        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    ret, thresh = cv2.threshold(img, 1, 255, cv2.THRESH_BINARY)

    kernel = np.ones((5, 5), dtype=np.uint8)
    thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)

    r, c = thresh.shape

    top_row = thresh[0, :]
    mid_row = thresh[int(r / 2), :]
    bottom_row = thresh[-1, :]

    top_row_start = np.where(top_row == 255)[0][0]
    top_row_end = np.where(top_row == 255)[0][-1]

    mid_row_start = np.where(mid_row == 255)[0][0]
    mid_row_end = np.where(mid_row == 255)[0][-1]

    left_fit = np.poly1d(np.polyfit([0, int(r / 2)], [top_row_start, mid_row_start], 1))
    right_fit = np.poly1d(np.polyfit([0, int(r / 2)], [top_row_end, mid_row_end], 1))

    bottom_row_start = int(left_fit(r))
    bottom_row_end = int(right_fit(r))

    # bottom_row_start = np.where(bottom_row == 255)[0][0]
    # bottom_row_end = np.where(bottom_row == 255)[0][-1]

    return (top_row_start, top_row_end), (bottom_row_start, bottom_row_end)


def get_bottom_contour(img, reduction=True, bottom_feature_ratio=1.7, show=False, bottom_percentile=BOTTOM_PERCENTILE):
    """
    This method is specifically designed for case 4 to get the bottom contour.
    :param img:  A BGR image without any annotation or markers
    :param reduction: Whether to use approximation for bottom contour separation, this is like a LPF
    :param bottom_feature_ratio: the amount of frame that the bottom spine occupies
    :return: The bottom half (approximated by default) contour of the spine, and the beginning height of the cropped
            image region
    """
    original_image = img.copy()
    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    h = int((img.shape[0] / bottom_feature_ratio) * (bottom_feature_ratio - 1))
    img = img[h:, :]
    thresh_value = pixel_by_percentile(img, bottom_percentile)
    _, th = cv2.threshold(img, thresh_value, 255, cv2.THRESH_BINARY)
    th = morph_closing(th, kernel_width=5, kernel_height=7)
    largest_binary = get_largest_cc(th)
    contours, _ = cv2.findContours(largest_binary, 1, 2)
    largest_contour_index = get_longest_contour(contours)
    if reduction:
        largest_contour = contour_reduction(contours[largest_contour_index])
    else:
        largest_contour = get_bottom_half(contours[largest_contour_index])

    largest_contour[:, 1] += h
    if show:
        contour_img = cv2.drawContours(original_image, [largest_contour], -1, (0, 255, 0), 2)
        cv2.imshow("Contour", contour_img)
        cv2.waitKey(0)
        cv2.destroyAllWindows()

    return largest_contour, h
